{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a full mission of basestation files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append('/Users/eddifying/Cloudfree/gitlab-cloudfree/seagliderOG1')\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seagliderOG1 import readers\n",
    "from seagliderOG1 import plotters\n",
    "from seagliderOG1 import convertOG1\n",
    "from seagliderOG1 import vocabularies\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dataset for dive number 285 is empty or invalid.\n",
      "Warning: Dataset for dive number 286 is empty or invalid.\n",
      "Warning: Dataset for dive number 416 is empty or invalid.\n",
      "Warning: Dataset for dive number 417 is empty or invalid.\n",
      "Warning: Dataset for dive number 418 is empty or invalid.\n",
      "sg016\n",
      "TypeError Invalid value for attr 'dtype': dtype('float64'). For serialization to netCDF files, its value must be of one of the following types: str, Number, ndarray, number, list, tuple\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(readers)\n",
    "importlib.reload(convertOG1)\n",
    "#input_loc = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/015/20040924/\"\n",
    "input_loc = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20040924/\"\n",
    "input_loc = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/004/20031002/\"\n",
    "input_loc = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/008/20031002/\"\n",
    "input_loc =  \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20050406/\"\n",
    "\n",
    "def process_and_save_data(input_location, save=False, output_dir='../data'):\n",
    "    # Load and concatenate all datasets from the server\n",
    "    list_datasets = readers.read_basestation(input_location)\n",
    "    \n",
    "    # Convert the list of datasets to OG1\n",
    "    ds_all = convertOG1.convert_to_OG1(list_datasets)\n",
    "    \n",
    "    if save:\n",
    "        # Generate the output file path\n",
    "        # Need to get the serial number of the platform for this\n",
    "#        output_file = os.path.join(output_dir, id_str + '_' + ds_all.start_date + '_delayed.nc')\n",
    "        output_file = os.path.join('../data', ds_all.attrs['id'] + '.nc')\n",
    "\n",
    "        # Check if the file exists and delete it if it does\n",
    "        if os.path.exists(output_file):\n",
    "            user_input = input(f\"File {output_file} already exists. Do you want to delete it? (yes/no): \")\n",
    "            if user_input.lower() != 'yes':\n",
    "                print(\"File not deleted. Exiting the process.\")\n",
    "                return ds_all\n",
    "            os.remove(output_file)\n",
    "        \n",
    "        # Save the dataset to a NetCDF file\n",
    "        convertOG1.save_dataset(ds_all, output_file)\n",
    "    \n",
    "    return ds_all\n",
    "\n",
    "# Example usage\n",
    "ds_all = process_and_save_data(input_loc, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "coordinate 'LONGITUDE' not present in all datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m processed_datasets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m---> 12\u001b[0m     ds_new, attr_warnings, sg_cal, dc_other, dc_log \u001b[38;5;241m=\u001b[39m \u001b[43mconvertOG1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_OG1_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     processed_datasets\u001b[38;5;241m.\u001b[39mappend(ds_new)\n\u001b[1;32m     15\u001b[0m concatenated_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat(processed_datasets, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_MEASUREMENTS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Cloudfree/gitlab-cloudfree/seagliderOG1/seagliderOG1/convertOG1.py:111\u001b[0m, in \u001b[0;36mconvert_to_OG1_dataset\u001b[0;34m(ds1, contrib_to_append)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Converts the dataset and updates its attributes.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m        - ordered_attributes (dict): The dataset with updated attributes.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# Convert the dataset and output also variables not included\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     ds_new, attr_warnings, sg_cal, dc_other, dc_log \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Create the attributes in order\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m#    ordered_attributes = update_dataset_attributes(ds1, contrib_to_append)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds_new, attr_warnings, sg_cal, dc_other, dc_log\n",
      "File \u001b[0;32m~/Cloudfree/gitlab-cloudfree/seagliderOG1/seagliderOG1/convertOG1.py:188\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[0;34m(ds1)\u001b[0m\n\u001b[1;32m    182\u001b[0m renamed_ds \u001b[38;5;241m=\u001b[39m convert_units(renamed_ds)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Add new variables to the dataset (GPS, divenum, PROFILE_NUMBER, PHASE)\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m#-----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Add the gps_info to the dataset\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Must be after split_by_unique_dims and after rename_dimensions\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m ds_new \u001b[38;5;241m=\u001b[39m \u001b[43madd_gps_info_to_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenamed_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgps_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Add the variable divenum.  Assumes present in the attributes of the original dataset\u001b[39;00m\n\u001b[1;32m    190\u001b[0m ds_new \u001b[38;5;241m=\u001b[39m add_dive_number(ds_new, divenum)\n",
      "File \u001b[0;32m~/Cloudfree/gitlab-cloudfree/seagliderOG1/seagliderOG1/convertOG1.py:416\u001b[0m, in \u001b[0;36madd_gps_info_to_dataset\u001b[0;34m(ds, gps_ds)\u001b[0m\n\u001b[1;32m    414\u001b[0m datasets\u001b[38;5;241m.\u001b[39mappend(ds)\n\u001b[1;32m    415\u001b[0m datasets\u001b[38;5;241m.\u001b[39mappend(gps_ds)\n\u001b[0;32m--> 416\u001b[0m ds_new \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mN_MEASUREMENTS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m ds_new \u001b[38;5;241m=\u001b[39m ds_new\u001b[38;5;241m.\u001b[39msortby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds_new\n",
      "File \u001b[0;32m~/micromamba/envs/glidertest_env/lib/python3.12/site-packages/xarray/core/concat.py:251\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dataarray_concat(\n\u001b[1;32m    240\u001b[0m         objs,\n\u001b[1;32m    241\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    249\u001b[0m     )\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_obj, Dataset):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dataset_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only concatenate xarray Dataset and DataArray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(first_obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/glidertest_env/lib/python3.12/site-packages/xarray/core/concat.py:593\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;66;03m# raise if coordinate not in all datasets\u001b[39;00m\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m coord_names:\n\u001b[0;32m--> 593\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    594\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m not present in all datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    595\u001b[0m             )\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m ensure_common_dims(variables, var_concat_dim_length)\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Try to concatenate the indexes, concatenate the variables when no index\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# is found on all datasets.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: coordinate 'LONGITUDE' not present in all datasets."
     ]
    }
   ],
   "source": [
    "importlib.reload(convertOG1)\n",
    "input_loc =  \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20050406/\"\n",
    "save=True\n",
    "# Troubleshooting - run outside a function\n",
    "# Load and concatenate all datasets from the server\n",
    "list_datasets = readers.read_basestation(input_loc)\n",
    "\n",
    "datasets = list_datasets\n",
    "# Convert the list of datasets to OG1\n",
    "processed_datasets = []\n",
    "for ds in datasets:\n",
    "    ds_new, attr_warnings, sg_cal, dc_other, dc_log = convertOG1.convert_to_OG1_dataset(ds)\n",
    "    processed_datasets.append(ds_new)\n",
    "\n",
    "concatenated_ds = xr.concat(processed_datasets, dim='N_MEASUREMENTS')\n",
    "concatenated_ds = concatenated_ds.sortby('TIME')\n",
    "\n",
    "# Apply attributes\n",
    "ordered_attributes = update_dataset_attributes(datasets[0], contrib_to_append)\n",
    "for key, value in ordered_attributes.items():\n",
    "    concatenated_ds.attrs[key] = value\n",
    "\n",
    "# Construct the platform serial number\n",
    "PLATFORM_SERIAL_NUMBER = 'sg' + concatenated_ds.attrs['id'][1:4]\n",
    "print(PLATFORM_SERIAL_NUMBER)\n",
    "concatenated_ds['PLATFORM_SERIAL_NUMBER'] = PLATFORM_SERIAL_NUMBER\n",
    "concatenated_ds['PLATFORM_SERIAL_NUMBER'].attrs['long_name'] = \"glider serial number\"\n",
    "\n",
    "# Construct the unique identifier attribute\n",
    "id = f\"{PLATFORM_SERIAL_NUMBER}_{concatenated_ds.start_date}_delayed\"\n",
    "concatenated_ds.attrs['id'] = id\n",
    "\n",
    "if save:\n",
    "    # Generate the output file path\n",
    "    # Need to get the serial number of the platform for this\n",
    "#        output_file = os.path.join(output_dir, id_str + '_' + ds_all.start_date + '_delayed.nc')\n",
    "    output_file = os.path.join('../data', concatenated_ds.attrs['id'] + '.nc')\n",
    "\n",
    "    # Check if the file exists and delete it if it does\n",
    "    if os.path.exists(output_file):\n",
    "        user_input = input(f\"File {output_file} already exists. Do you want to delete it? (yes/no): \")\n",
    "        if user_input.lower() != 'yes':\n",
    "            print(\"File not deleted. Exiting the process.\")\n",
    "            return ds_all\n",
    "        os.remove(output_file)\n",
    "    \n",
    "    # Save the dataset to a NetCDF file\n",
    "    convertOG1.save_dataset(concatenated_ds, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets\n",
    "coordinates_dict = {i: list(ds.coords) for i, ds in enumerate(processed_datasets)}\n",
    "coordinates_dict\n",
    "\n",
    "missing_longitude = [i for i, coords in coordinates_dict.items() if 'LONGITUDE' not in coords]\n",
    "missing_longitude\n",
    "\n",
    "datasets_with_longitude = [i for i, coords in coordinates_dict.items() if 'LONGITUDE' in coords]\n",
    "datasets_with_longitude\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skipped_profile', 'sg_cal_volmax', 'sg_cal_vbd_min_cnts', 'sg_cal_vbd_max_cnts', 'sg_cal_vbd_cnts_per_cc', 'sg_cal_therm_expan', 'sg_cal_t_j', 'sg_cal_t_i', 'sg_cal_t_h', 'sg_cal_t_g', 'sg_cal_roll_min_cnts', 'sg_cal_roll_max_cnts', 'sg_cal_rho0', 'sg_cal_pump_rate_slope', 'sg_cal_pump_rate_intercept', 'sg_cal_pump_power_slope', 'sg_cal_pump_power_intercept', 'sg_cal_pitch_min_cnts', 'sg_cal_pitch_max_cnts', 'sg_cal_mass', 'sg_cal_hd_c', 'sg_cal_hd_b', 'sg_cal_hd_a', 'sg_cal_ctcor', 'sg_cal_cpcor', 'sg_cal_c_j', 'sg_cal_c_i', 'sg_cal_c_h', 'sg_cal_c_g', 'sg_cal_abs_compress', 'sg_cal_Soc', 'sg_cal_Pcor', 'sg_cal_Foffset', 'sg_cal_E', 'sg_cal_C', 'sg_cal_B', 'sg_cal_A', 'reviewed', 'log__XMS_TOUTs', 'log__XMS_NAKs', 'log__SM_DEPTHo', 'log__SM_ANGLEo', 'log__CALLS', 'log_VBD_PUMP_AD_RATE_SURFACE', 'log_VBD_PUMP_AD_RATE_APOGEE', 'log_VBD_MIN', 'log_VBD_MAXERRORS', 'log_VBD_MAX', 'log_VBD_CNV', 'log_VBD_BLEED_AD_RATE', 'log_USE_BATHY', 'log_UNCOM_BLEED', 'log_T_TURN_SAMPINT', 'log_T_TURN', 'log_T_RSLEEP', 'log_T_NO_W', 'log_T_MISSION', 'log_T_GPS_CHARGE', 'log_T_GPS_ALMANAC', 'log_T_GPS', 'log_T_DIVE', 'log_TGT_RADIUS', 'log_TCM_TEMP', 'log_SPEED_FACTOR', 'log_SM_CC', 'log_R_STBD_OVSHOOT', 'log_R_PORT_OVSHOOT', 'log_ROLL_MIN', 'log_ROLL_MAX', 'log_ROLL_CNV', 'log_ROLL_AD_RATE', 'log_RHO', 'log_P_OVSHOOT', 'log_PITCH_VBD_SHIFT', 'log_PITCH_MIN', 'log_PITCH_MAX', 'log_PITCH_GAIN', 'log_PITCH_CNV', 'log_PITCH_AD_RATE', 'log_N_NOCOMM', 'log_N_GPS', 'log_N_FILEKB', 'log_MAX_BUOY', 'log_KALMAN_USE', 'log_ID', 'log_HUMID', 'log_HEAD_ERRBAND', 'log_HD_C', 'log_HD_B', 'log_HD_A', 'log_GLIDE_SLOPE', 'log_D_TGT', 'log_D_SURF', 'log_D_OFFGRID', 'log_D_NO_BLEED', 'log_D_GRID', 'log_D_FLARE', 'log_D_ABORT', 'log_DIVE', 'log_C_VBD', 'log_C_ROLL_DIVE', 'log_C_ROLL_CLIMB', 'log_C_PITCH', 'log_COURSE_BIAS', 'log_COMM_SEQ', 'log_CALL_WAIT', 'log_CALL_TRIES', 'log_CALL_NDIVES', 'log_APOGEE_PITCH', 'log_AH0_24V', 'log_AH0_10V', 'wlbb2f', 'trajectory', 'sg_cal_mission_title', 'sg_cal_id_str', 'sg_cal_calibcomm_oxygen', 'sg_cal_calibcomm', 'sbe41', 'log_gps_time', 'log_gps_lon', 'log_gps_lat', 'log_TGT_NAME', 'log_TGT_LATLONG', 'log_SPEED_LIMITS', 'log_SM_CCo', 'log_SENSOR_SECS', 'log_SENSOR_MAMPS', 'log_MHEAD_RNG_PITCHd_Wd', 'log_KALMAN_Y', 'log_KALMAN_X', 'log_KALMAN_CONTROL', 'log_GPS2', 'log_GPS1', 'log_GPS', 'log_ERRORS', 'log_DEVICE_SECS', 'log_DEVICE_MAMPS', 'log_DATA_FILE_SIZE', 'log_24V_AH', 'log_10V_AH', 'glider', 'gc_vbd_secs', 'gc_vbd_i', 'gc_vbd_ctl', 'gc_vbd_ad', 'gc_st_secs', 'gc_roll_secs', 'gc_roll_i', 'gc_roll_ad', 'gc_pitch_secs', 'gc_pitch_i', 'gc_pitch_ctl', 'gc_pitch_ad', 'gc_ob_vertv', 'gc_gcphase', 'gc_end_secs', 'gc_depth', 'gc_data_pts', 'eng_wlbb2f_redRef', 'eng_wlbb2f_redCount', 'eng_wlbb2f_fluorCount', 'eng_wlbb2f_blueRef', 'eng_wlbb2f_blueCount', 'eng_wlbb2f_VFtemp', 'eng_vbdCC', 'eng_sbect_tempFreq', 'eng_sbect_condFreq', 'eng_rollCtl', 'eng_rollAng', 'eng_pitchCtl', 'eng_pitchAng', 'eng_head', 'eng_elaps_t_0000', 'eng_elaps_t', 'eng_depth', 'directives']\n",
      "<xarray.Dataset>\n",
      "Dimensions:                       (sg_data_point: 163, trajectory: 1,\n",
      "                                   gps_info: 3, gc_event: 7)\n",
      "Coordinates:\n",
      "  * trajectory                    (trajectory) int32 1\n",
      "    longitude                     (sg_data_point) float64 ...\n",
      "    latitude                      (sg_data_point) float64 ...\n",
      "    ctd_time                      (sg_data_point) datetime64[ns] ...\n",
      "    ctd_depth                     (sg_data_point) float64 ...\n",
      "Dimensions without coordinates: sg_data_point, gps_info, gc_event\n",
      "Data variables: (12/231)\n",
      "    surface_curr_north            float64 ...\n",
      "    surface_curr_east             float64 ...\n",
      "    start_of_climb_time           timedelta64[ns] ...\n",
      "    sg_cal_volmax                 float64 ...\n",
      "    sg_cal_vbd_min_cnts           int32 ...\n",
      "    sg_cal_vbd_max_cnts           int32 ...\n",
      "    ...                            ...\n",
      "    conductivity                  (sg_data_point) float64 ...\n",
      "    buoyancy                      (sg_data_point) float64 ...\n",
      "    GPSE_qc                       |S1 ...\n",
      "    GPS2_qc                       |S1 ...\n",
      "    GPS1_qc                       |S1 ...\n",
      "    CTD_qc                        |S1 ...\n",
      "Attributes: (12/58)\n",
      "    quality_control_version:         1.1\n",
      "    base_station_micro_version:      3705\n",
      "    time_coverage_resolution:        PT1S\n",
      "    geospatial_vertical_max:         55.00316329589315\n",
      "    sea_name:                        Labrador Sea\n",
      "    mission:                         1\n",
      "    ...                              ...\n",
      "    disclaimer:                      Data has not been reviewed and is provid...\n",
      "    geospatial_vertical_positive:    no\n",
      "    date_created:                    2013-08-01T03:08:27Z\n",
      "    geospatial_vertical_units:       meter\n",
      "    dive_number:                     1\n",
      "    history:                         Processing start:\\n03:06:27 01 Aug 2013 ...\n"
     ]
    }
   ],
   "source": [
    "print(list(ds.variables.keys()))\n",
    "print(datasets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m concatenated_ds \u001b[38;5;241m=\u001b[39m concatenated_ds\u001b[38;5;241m.\u001b[39msortby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Generate the output file path\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Need to get the serial number of the platform for this\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#        output_file = os.path.join(output_dir, id_str + '_' + ds_all.start_date + '_delayed.nc')\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mconcatenated_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Check if the file exists and delete it if it does\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_file):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "concatenated_ds = xr.concat(processed_datasets, dim='N_MEASUREMENTS')\n",
    "concatenated_ds = concatenated_ds.sortby('TIME')\n",
    "# Generate the output file path\n",
    "# Need to get the serial number of the platform for this\n",
    "#        output_file = os.path.join(output_dir, id_str + '_' + ds_all.start_date + '_delayed.nc')\n",
    "output_file = os.path.join('../data', concatenated_ds.attrs['id'] + '.nc')\n",
    "\n",
    "# Check if the file exists and delete it if it does\n",
    "if os.path.exists(output_file):\n",
    "    user_input = input(f\"File {output_file} already exists. Do you want to delete it? (yes/no): \")\n",
    "    if user_input.lower() != 'yes':\n",
    "        print(\"File not deleted. Exiting the process.\")\n",
    "        return concatenated_ds\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Save the dataset to a NetCDF file\n",
    "convertOG1.save_dataset(concatenated_ds, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
