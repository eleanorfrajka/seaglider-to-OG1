{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# Demo: Convert single basestation *.nc file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9729d-4db2-419c-bbc2-a2078fc9b7dc",
   "metadata": {},
   "source": [
    "This notebook converts sg015 data from the Labrador Sea in September 2024 into OG1 format.\n",
    "\n",
    "- OG1 format is a newly agreed format (since June 2024) for glider data sets from various platforms (e.g., Seaglider, Slocum, Seaexplorer).  It lives on github here: (https://github.com/OceanGlidersCommunity/OG-format-user-manual).\n",
    "- OG1 manual: https://oceangliderscommunity.github.io/OG-format-user-manual/OG_Format.html\n",
    "\n",
    "Process:\n",
    "\n",
    "1. For one basestation dataset, split the dataset by dimension (`split_ds`)\n",
    "3. Transform into OG1 format: dataset with dims `sg_data_point`\n",
    "    - Change the dimension to `N_MEASUREMENTS`\n",
    "    - Rename variables according to `vocabularies.standard_names` \n",
    "    - Assign variable attributes according to `vocabularies.vocab_attrs`.  (Note: This *could* go wrong since it makes assumptions about the input variables. May need additional handling.)\n",
    "4. Add missing mandatory variables: \n",
    "    - From `split_ds[(gps_info,)]`, add the `LATITUDE_GPS`, `LONGITUDE_GPS` and `TIME_GPS` (Note: presently `TIME_GPS` is stripped before saving, but `TIME` values contain `TIME_GPS`)\n",
    "    - Create `PROFILE_NUMBER` and `PHASE`\n",
    "    - Calculate `DEPTH_Z` which is positive up\n",
    "5. Update attributes for the file. \n",
    "    - Combines `creator` and `contributor` from original attributes into `contributor`\n",
    "    - Adds `contributing_institutions` based on `institution`\n",
    "    - Reformats time in `time_coverage_*` and `start_time`--> `start_date`\n",
    "    - Adds `date_modified`\n",
    "    - Renames `comments`-->`history`, `site`-->`summary`\n",
    "    - Adds `title`, `platform`, `platform_vocabulary`, `featureType`, `Conventions`, `rtqc_method*` according to OceanGliders format\n",
    "    - Retains `naming_authority`, `institution`, `project`, `geospatial_*` as OG attributes\n",
    "    - Retains extra attributes: `license`, `keywords`, `keywords_vocabulary`, `file_version`, `acknowledgement`, `date_created`, `disclaimer`\n",
    "\n",
    "Future behaviour to be added:\n",
    "\n",
    "6. Retain the variables starting with `sg_cal` and check whether they vary over the mission (shouldn't)\n",
    "6. Add sensors, using information in the `split_ds` with no dimensions\n",
    "    - Need (from sg_cal_constants: `sg_cal` plus `volmax`, `vbd_cnts_per_cc`, `therm_expan`, `t_*`, `mass`, `hd_*`, `ctcor`, `cpcor`, `c_*`, `abs_compress`, `a`, `Tcor`, `Soc`, `Pcor`, `Foffset`)\n",
    "    - Maybe also `reviewed`, `magnetic_variation` (which will change with position), `log_D_FLARE`, `flight_avg_speed_north` and `flight_avg_speed_east` also with `_gsm`, `depth_avg_curr_north` and `depth_avg_curr_east` also with `_gsm`, \n",
    "    `wlbb2f` - means sensor\n",
    "    `sg_cal_mission_title`\n",
    "    `sg_cal_id_str`\n",
    "    `calibcomm_oxygen`\n",
    "    `calibcomm`\n",
    "    `sbe41` means ??\n",
    "    `hdm_qc`\n",
    "    `glider`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c437da6-c3b3-4c48-b272-ee5b8ac27f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is for development purposes\n",
    "import sys\n",
    "# Change to your path\n",
    "sys.path.append('/Users/eddifying/Cloudfree/gitlab-cloudfree/seagliderOG1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fc4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from seagliderOG1 import plotters\n",
    "from seagliderOG1 import readers\n",
    "from seagliderOG1 import convertOG1\n",
    "from seagliderOG1 import vocabularies\n",
    "import xarray as xr\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96457f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these to existing attributes - update to your details\n",
    "contrib_to_append = {\n",
    "    'contributor_name': 'Eleanor Frajka-Williams',\n",
    "    'contributor_email': 'eleanorfrajka@gmail.com',\n",
    "    'contributor_role': 'Data scientist',\n",
    "    'contributor_role_vocabulary': 'http://vocab.nerc.ac.uk/search_nvs/W08',\n",
    "    'contributing_institutions': 'University of Hamburg - Institute of Oceanography',\n",
    "    'contributing_institutions_vocabulary': 'https://edmo.seadatanet.org/report/1156',\n",
    "    'contributing_institutions_role': 'Data scientist',\n",
    "    'contributing_institutions_role_vocabulary': 'http://vocab.nerc.ac.uk/search_nvs/W08',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd041858-c498-4654-a7c8-1731beb839fc",
   "metadata": {},
   "source": [
    "## Load Seaglider data in basestation format\n",
    "\n",
    "Test case build on a file which was written in 2013 by basestation v2.8 into nodc format template v0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac290a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the server where data are located\n",
    "if 1:\n",
    "    input_loc = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/015/20040924/\"\n",
    "    input_loc = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100729/\"\n",
    "else:\n",
    "    input_loc = '/Users/eddifying/Dropbox/data/sg015-ncei-download/'\n",
    "\n",
    "# Load datasets from the server, optionally specifying the range of profiles to load\n",
    "start_dive = 1\n",
    "end_dive = 10\n",
    "\n",
    "# --- List the data\n",
    "list_datasets = readers.read_basestation(input_loc, 1, 10)\n",
    "\n",
    "# Pick one basestation xarray dataset to work with\n",
    "ds1 = list_datasets[0]\n",
    "\n",
    "# --- Convert the data\n",
    "ds_single_OG1 = convertOG1.convert_to_OG1(list_datasets, contrib_to_append)\n",
    "\n",
    "# --- Output file\n",
    "# Check a location for the output file\n",
    "output_file = os.path.join('../data', 'demo_single_test.nc')\n",
    "# If it's already there, remove it first\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Write the file\n",
    "# This writer catches errors in data types (DType errors) when using xr.to_netcdf()\n",
    "# The solution is to convert them to strings, which may be undesired behaviour\n",
    "convertOG1.save_dataset(ds_single_OG1, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18c985",
   "metadata": {},
   "source": [
    "### Same process, but breaking out sub-functions\n",
    "\n",
    "This is the same process as above (contained in `convertOG1.convert_to_OG1`), but breaking out to access the sub-functions individually.  This way you can inspect the process as it goes along, and also inspect some of the data which did not make it into the final dataset:\n",
    "\n",
    "- `sg_cal` - details from `sg_calib_constants.m`, \n",
    "- `dc_log` - log events, and \n",
    "- `dc_other` - random other variables that were in the basestation file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset and output also variables not included\n",
    "ds_new, attr_warnings, sg_cal, dc_other, dc_log = convertOG1.process_dataset(ds1)\n",
    "\n",
    "# Create the list of attributes in order\n",
    "ordered_attributes = convertOG1.update_dataset_attributes(ds1, contrib_to_append)\n",
    "\n",
    "for key, value in ordered_attributes.items():\n",
    "    ds_new.attrs[key] = value\n",
    "\n",
    "# Construct the platform serial number\n",
    "PLATFORM_SERIAL_NUMBER = 'sg' + ds_new.attrs['id'][1:4]\n",
    "ds_new['PLATFORM_SERIAL_NUMBER'] = PLATFORM_SERIAL_NUMBER\n",
    "ds_new['PLATFORM_SERIAL_NUMBER'].attrs['long_name'] = \"glider serial number\"\n",
    "\n",
    "# Construct the unique identifier attribute\n",
    "id = f\"{PLATFORM_SERIAL_NUMBER}_{ds_new.start_date}_delayed\"\n",
    "ds_new.attrs['id'] = id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9e607",
   "metadata": {},
   "source": [
    "### Save the data \n",
    "\n",
    "As above, but builds the filename out of parameters in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotters.show_attributes(ds_new)\n",
    "## Save the dataset to a NetCDF file\n",
    "# Check if the file exists and delete it if it does\n",
    "\n",
    "output_file = os.path.join('../data', 'demo_single_test2.nc')\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Save the dataset to a NetCDF file\n",
    "convertOG1.save_dataset(ds_new, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
