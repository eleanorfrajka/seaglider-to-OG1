{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9729d-4db2-419c-bbc2-a2078fc9b7dc",
   "metadata": {},
   "source": [
    "\n",
    "The purpose of this notebook is to create a minimum working example of seaglider data in OG1 format. The test case is to convert sg015 data from the Labrador Sea in September 2004.\n",
    "\n",
    "- OG1 format is a newly agreed format (since June 2024) for glider data sets from various platforms (e.g., Seaglider, Slocum, Seaexplorer).  It lives on github here: (https://github.com/OceanGlidersCommunity/OG-format-user-manual).\n",
    "- OG1 manual: https://oceangliderscommunity.github.io/OG-format-user-manual/OG_Format.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8427334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append('/Users/eddifying/Cloudfree/gitlab-cloudfree/seagliderOG1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c437da6-c3b3-4c48-b272-ee5b8ac27f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from seagliderOG1 import fetchers\n",
    "from seagliderOG1 import tools\n",
    "from seagliderOG1 import plotters\n",
    "import xarray as xr\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd041858-c498-4654-a7c8-1731beb839fc",
   "metadata": {},
   "source": [
    "## Load Seaglider data in native format\n",
    "\n",
    "This has three ways to load a glider dataset.\n",
    "\n",
    "Load an example dataset using `seagliderOG1.fetchers.load_sample_dataset`\n",
    "\n",
    "Alternatively, use your own with e.g. `ds = xr.open_dataset('/path/to/yourfile.nc')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b310d",
   "metadata": {},
   "source": [
    "### Load a sample dataset\n",
    "\n",
    "These data are hosted (currently) on dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0eae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available datasets\n",
    "file_list = ['p0150500_20050213.nc', 'p0150501_20050213.nc', 'p0150502_20050214.nc', 'p0150503_20050214.nc', 'p0150504_20050215.nc'];\n",
    "\n",
    "# Loads one dataset (p0150500_20050213.nc)\n",
    "ds = fetchers.load_sample_dataset()\n",
    "plotters.plot_profile_depth(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a27f3",
   "metadata": {},
   "source": [
    "### Load dataset from local machine\n",
    "\n",
    "- For local data in the directory `input_dir`\n",
    "- Creates a plot of ctd_depth against ctd_time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d202485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = \"/Users/eddifying/Dropbox/data/sg015-ncei-download\"\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "ds_all = fetchers.load_dataset_from_directory(input_dir, start_profile=500, end_profile=501)\n",
    "\n",
    "# Simple plot of depth against time\n",
    "plotters.plot_profile_depth(ds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f9e81",
   "metadata": {},
   "source": [
    "### Load data from the NCEI server\n",
    "\n",
    "- Data from the sg015 mission in the Labrador Sea (https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.nodc:0111844), dataset identifier gov.noaa.nodc:0111844.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac290a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the server where data are located\n",
    "server = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/015/20040924/\"\n",
    "\n",
    "# This was necessary to get an initial file list\n",
    "# mylist = fetchers.list_files_in_https_server(server)\n",
    "# fetchers.create_pooch_registry_from_directory(\"/Users/eddifying/Dropbox/data/sg015-ncei-download/\")\n",
    "\n",
    "# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\n",
    "ds_all = fetchers.load_dataset_from_online(server, start_profile=500, end_profile=504)\n",
    "\n",
    "# Simple plot of depth against time\n",
    "plotters.plot_profile_depth(ds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17a794",
   "metadata": {},
   "source": [
    "## Start to think about renaming variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561d1f1",
   "metadata": {},
   "source": [
    "### Check what variables are in the file\n",
    "\n",
    "- Here, I found it easier to use glidertools (https://glidertools.readthedocs.io/en/latest/loading.html#working-with-seaglider-base-station-files) to get a quick look at what's in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef988d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the variables from one file\n",
    "filenames = input_dir + \"/\" + file_list[0]\n",
    "print(filenames)\n",
    "\n",
    "plotters.show_variables(filenames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053a20b",
   "metadata": {},
   "source": [
    "### Check the attributes in the basestation file\n",
    "\n",
    "There was no equivalent in glidertools, so I wrote one and put it in `seagliderOG1.plotters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['p0150500_20050213.nc', 'p0150501_20050213.nc', 'p0150502_20050214.nc', 'p0150503_20050214.nc', 'p0150504_20050215.nc'];\n",
    "filenames = input_dir + \"/\" + file_list[0]\n",
    "plotters.show_attributes(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee45495",
   "metadata": {},
   "source": [
    "### Assign new attributes\n",
    "\n",
    "Some of the attributes in the basestation netcdf file can be translated fairly easily into the OG1 format.  This is done in `tools.modify_attributes`.  At present, the \"extra\" attributes are retained at the bottom of the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = \"/Users/eddifying/Dropbox/data/sg015-ncei-download\"\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "ds_all = fetchers.load_dataset_from_directory(input_dir, start_profile=500, end_profile=501)\n",
    "\n",
    "# Generate the dictionaries and lists to change the attributes\n",
    "attr_to_add, attr_as_is, attr_to_change, attr_to_remove = tools.generate_attributes(ds_all)\n",
    "\n",
    "# Assign new values to the attributes\n",
    "ds_all = tools.modify_attributes(ds_all, attr_to_add, attr_as_is, attr_to_change, attr_to_remove)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63937bd8",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Rename variables\n",
    "\n",
    "This conversion is incomplete.  See e.g., the tools.convert_to_og1() which is based on VOTO tools and not only names variables but also adds attributes to those variables.  This should be done instead of the \"comments\" which are in the basestation netcdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionaries for renaming\n",
    "#ds_single = xr.open_dataset(file_list[0])\n",
    "\n",
    "dims_rename_dict = {'sg_data_point': 'N_MEASUREMENTS'}\n",
    "coords_rename_dict = {\n",
    "    'longitude': 'LONGITUDE',\n",
    "    'latitude': 'LATITUDE',\n",
    "    'ctd_time': 'TIME',\n",
    "    'ctd_depth': 'DEPTH'\n",
    "}\n",
    "vars_rename_dict = {\n",
    "    'conductivity': 'CNDC',\n",
    "    'temperature': 'TEMP',\n",
    "    'salinity': 'PSAL', # after thermal lag correction\n",
    "#    'conductivity_qc': 'CNDC_QC',\n",
    "#    'salinity_qc': 'PSAL_QC',\n",
    "#    'temperature_qc': 'TEMP_QC',\n",
    "    'vert_speed': 'VERT_GLIDER_SPEED', # This is using the hdm\n",
    "    'horz_speed': 'HORZ_GLIDER_SPEED', # This is using the hdm\n",
    "    'density': 'DENSITY',\n",
    "}\n",
    "\n",
    "def create_renamed_dataset(ds, dims_rename_dict, coords_rename_dict, vars_rename_dict):\n",
    "    # Apply renaming using the dictionaries\n",
    "    ds_renamed = ds.rename_dims(dims_rename_dict)\n",
    "    ds_renamed = ds_renamed.rename_vars(coords_rename_dict)\n",
    "    ds_renamed = ds_renamed.rename_vars(vars_rename_dict)\n",
    "    \n",
    "    # Remove variables not in vars_rename_dict().values\n",
    "    vars_to_keep = set(vars_rename_dict.values())\n",
    "    ds_renamed = ds_renamed[vars_to_keep]\n",
    "    return ds_renamed\n",
    "\n",
    "# Example usage\n",
    "ds_renamed = create_renamed_dataset(ds_new_att, dims_rename_dict, coords_rename_dict, vars_rename_dict)\n",
    "print(ds_renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9e607",
   "metadata": {},
   "source": [
    "## Check the final dataset\n",
    "\n",
    "At the moment, since the plotters.show_attributes() and plotters.show_variables() are designed to work with netcdf files, I write the xarray dataset to netcdf before loading it and checking the attributes and variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Save the dataset to a NetCDF file\n",
    "# Check if the file exists and delete it if it does\n",
    "output_file = os.path.join('../data', 'test.nc')\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Save the dataset to a NetCDF file\n",
    "ds_renamed.to_netcdf(output_file, mode='w', format='NETCDF4_CLASSIC')\n",
    "\n",
    "# Show the attributes of the saved NetCDF file\n",
    "plotters.show_attributes(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speeds(ds):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "    # Plot horizontal speed\n",
    "    ax[0].plot(ds['ctd_time'], ds['horz_speed'], label='Horizontal Speed', color='b')\n",
    "    ax[0].set_ylabel('Horizontal Speed (m/s)')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot vertical speed\n",
    "    ax[1].plot(ds['ctd_time'], ds['vert_speed'], label='Vertical Speed', color='r')\n",
    "    ax[1].set_ylabel('Vertical Speed (m/s)')\n",
    "    ax[1].set_xlabel('Time')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_speeds(ds_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
