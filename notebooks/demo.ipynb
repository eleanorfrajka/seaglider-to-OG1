{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9729d-4db2-419c-bbc2-a2078fc9b7dc",
   "metadata": {},
   "source": [
    "\n",
    "The purpose of this notebook is to create a minimum working example of seaglider data in OG1 format. The test case is to convert sg015 data from the Labrador Sea in September 2004.\n",
    "\n",
    "- OG1 format is a newly agreed format (since June 2024) for glider data sets from various platforms (e.g., Seaglider, Slocum, Seaexplorer).  It lives on github here: (https://github.com/OceanGlidersCommunity/OG-format-user-manual).\n",
    "- OG1 manual: https://oceangliderscommunity.github.io/OG-format-user-manual/OG_Format.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8427334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append('/Users/eddifying/Cloudfree/gitlab-cloudfree/seagliderOG1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c437da6-c3b3-4c48-b272-ee5b8ac27f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from seagliderOG1 import fetchers\n",
    "from seagliderOG1 import tools\n",
    "from seagliderOG1 import plotters\n",
    "from seagliderOG1 import vocabularies\n",
    "import xarray as xr\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd041858-c498-4654-a7c8-1731beb839fc",
   "metadata": {},
   "source": [
    "## Load Seaglider data in native format\n",
    "\n",
    "This has three ways to load a glider dataset.\n",
    "\n",
    "Load an example dataset using `seagliderOG1.fetchers.load_sample_dataset`\n",
    "\n",
    "Alternatively, use your own with e.g. `ds = xr.open_dataset('/path/to/yourfile.nc')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b310d",
   "metadata": {},
   "source": [
    "### Load a sample dataset\n",
    "\n",
    "These data are hosted (currently) on dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0eae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available datasets\n",
    "file_list = ['p0150500_20050213.nc', 'p0150501_20050213.nc', 'p0150502_20050214.nc', 'p0150503_20050214.nc', 'p0150504_20050215.nc'];\n",
    "\n",
    "# Loads one dataset (p0150500_20050213.nc)\n",
    "ds = fetchers.load_sample_dataset()\n",
    "\n",
    "# Check the results\n",
    "plotters.plot_profile_depth(ds)\n",
    "#plotters.show_variables_xarray(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a27f3",
   "metadata": {},
   "source": [
    "### Load dataset from local machine\n",
    "\n",
    "- For local data in the directory `input_dir`\n",
    "- Creates a plot of ctd_depth against ctd_time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d202485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = \"/Users/eddifying/Dropbox/data/sg015-ncei-download\"\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "ds_all = fetchers.load_dataset(input_dir, start_profile=500, end_profile=501)\n",
    "\n",
    "# Simple plot of depth against time\n",
    "plotters.plot_profile_depth(ds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f9e81",
   "metadata": {},
   "source": [
    "### Load data from the NCEI server\n",
    "\n",
    "- Data from the sg015 mission in the Labrador Sea (https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.nodc:0111844), dataset identifier gov.noaa.nodc:0111844.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac290a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the server where data are located\n",
    "server = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/015/20040924/\"\n",
    "\n",
    "# This was necessary to get an initial file list\n",
    "# mylist = fetchers.list_files_in_https_server(server)\n",
    "# fetchers.create_pooch_registry_from_directory(\"/Users/eddifying/Dropbox/data/sg015-ncei-download/\")\n",
    "\n",
    "# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\n",
    "ds_all = fetchers.load_dataset(server, start_profile=500, end_profile=504)\n",
    "\n",
    "#plotters.show_contents(ds_all)\n",
    "# Simple plot of depth against time\n",
    "plotters.plot_depth_colored(ds_all, color_by='trajectory')#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17a794",
   "metadata": {},
   "source": [
    "## Start to think about renaming variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561d1f1",
   "metadata": {},
   "source": [
    "### Check what variables are in the file\n",
    "\n",
    "- Here, I found it easier to use glidertools (https://glidertools.readthedocs.io/en/latest/loading.html#working-with-seaglider-base-station-files) to get a quick look at what's in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef988d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the variables from one file\n",
    "importlib.reload(plotters)\n",
    "filename = input_dir + \"/\" + file_list[0]\n",
    "\n",
    "# Show the result\n",
    "#plotters.show_contents(filename, 'attrs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053a20b",
   "metadata": {},
   "source": [
    "### Check the attributes in the basestation file\n",
    "\n",
    "There was no equivalent in glidertools, so I wrote one and put it in `seagliderOG1.plotters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['p0150500_20050213.nc', 'p0150501_20050213.nc', 'p0150502_20050214.nc', 'p0150503_20050214.nc', 'p0150504_20050215.nc'];\n",
    "filenames = input_dir + \"/\" + file_list[0]\n",
    "\n",
    "# Show the result\n",
    "#plotters.show_contents(filenames,'vars')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what we're going to delete in concatenating datasets with fetchers.load_dataset()\n",
    "\n",
    "# Load everything from the raw basestation file\n",
    "def load_netcdf_file(source, profile_number=500):\n",
    "\n",
    "    if source.startswith(\"http://\") or source.startswith(\"https://\"):\n",
    "        # Create a Pooch object to manage the remote files\n",
    "        data_source_online = pooch.create(\n",
    "            path=pooch.os_cache(\"seagliderOG1_online\"),\n",
    "            base_url=source,\n",
    "            registry=None,\n",
    "        )\n",
    "    filenames = []\n",
    "    datasets = []\n",
    "\n",
    "    for file in file_list:\n",
    "        if file.endswith(\".nc\"):\n",
    "            file_profile_num = int(file.split(\"_\")[0][4:])\n",
    "            if file_profile_num == profile_number:\n",
    "                    filenames.append(file)            \n",
    "\n",
    "    for file in filenames:\n",
    "        if source.startswith(\"http://\") or source.startswith(\"https://\"):\n",
    "            ds = fetchers.load_sample_dataset(file)\n",
    "        else:\n",
    "            ds = xr.open_dataset(os.path.join(source, file))\n",
    "\n",
    "    return ds\n",
    "\n",
    "# Load one dataset\n",
    "file_list = ['p0150500_20050213.nc']\n",
    "filenames = input_dir + \"/\" + file_list[0]\n",
    "ds = load_netcdf_file(input_dir, 500)\n",
    "\n",
    "# Separate what will be dropped in fetchers.load_dataset()\n",
    "#non_data = extract_non_sg_data_point_vars(ds)\n",
    "#print(non_data)\n",
    "\n",
    "# Check what dimensions they correspond to (everything without dimension sg_data_point is dropped)\n",
    "new_ds = fetchers.extract_non_sg_data_point_vars(ds)\n",
    "#plotters.show_contents(new_ds)\n",
    "\n",
    "# Show the keys (dimension names)\n",
    "print(new_ds.keys())\n",
    "\n",
    "# What variables are these?\n",
    "plotters.show_variables_by_dimension(ds, dimension_name='gc_event')\n",
    "\n",
    "# Some variables (like dive_number stored in 'trajectory' should be repeated for each sg_data_point)\n",
    "# Extract the value of the variable with dimensions of trajectory\n",
    "trajectory_var = ds['trajectory'].values\n",
    "\n",
    "# Expand its length to match sg_data_point\n",
    "expanded_trajectory_var = np.repeat(trajectory_var, ds.dims['sg_data_point'])\n",
    "\n",
    "# Insert it as a new variable in the ds dataset with dimension sg_data_point\n",
    "ds['trajectory_new'] = (['sg_data_point'], expanded_trajectory_var)\n",
    "\n",
    "# Other variables, like log_gps_lat and log_gps_lon should only appear at the nearest point in time\n",
    "# This is done with the function fetchers.add_gps_coordinates()\n",
    "\n",
    "# Example usage\n",
    "#plotters.plot_depth_colored(ds, color_by='trajectory_new')\n",
    "\n",
    "#plotters.show_variables_by_dimension(ds, dimension_name='trajectory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to ds\n",
    "ds = fetchers.add_gps_coordinates(ds)\n",
    "\n",
    "# Check the result\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot ctd_depth against ctd_time using a black line\n",
    "plt.plot(ds['ctd_time'], ds['ctd_depth'], 'k-', label='CTD Depth')\n",
    "\n",
    "# Plot ctd_depth against ctd_time where gps_lat is non NaN, with a colored red circle\n",
    "non_nan_indices = ~np.isnan(ds['gps_lat'])\n",
    "plt.plot(ds['ctd_time'][non_nan_indices], ds['ctd_depth'][non_nan_indices], 'ro', label='GPS Lat Non-NaN')\n",
    "\n",
    "plt.xlabel('CTD Time')\n",
    "plt.ylabel('CTD Depth')\n",
    "plt.legend()\n",
    "plt.title('CTD Depth vs Time')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have depth increasing downwards\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee45495",
   "metadata": {},
   "source": [
    "### Assign new attributes\n",
    "\n",
    "Some of the attributes in the basestation netcdf file can be translated fairly easily into the OG1 format.  This is done in `tools.modify_attributes`.  At present, the \"extra\" attributes are retained at the bottom of the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = \"/Users/eddifying/Dropbox/data/sg015-ncei-download\"\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "ds_all = fetchers.load_dataset(input_dir, start_profile=500, end_profile=501)\n",
    "\n",
    "# Generate the dictionaries and lists to change the attributes\n",
    "attr_to_add, attr_as_is, attr_to_change, attr_to_remove = tools.generate_attributes(ds_all)\n",
    "\n",
    "# Assign new values to the attributes\n",
    "ds_all = tools.modify_attributes(ds_all, attr_to_add, attr_as_is, attr_to_change, attr_to_remove)\n",
    "\n",
    "# Show the result\n",
    "#plotters.show_contents(ds_all)\n",
    "plotters.plot_depth_colored(ds_all,'salinity')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63937bd8",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Rename variables\n",
    "\n",
    "This conversion is incomplete.  See e.g., the tools.convert_to_og1() which is based on VOTO tools and not only names variables but also adds attributes to those variables.  This should be done instead of the \"comments\" which are in the basestation netcdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionaries for renaming\n",
    "# These are in vocabularies.py\n",
    "\n",
    "# Example usage\n",
    "ds_renamed = tools.create_renamed_dataset(ds_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61469c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_renamed = tools.assign_profile_number(ds_renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9e607",
   "metadata": {},
   "source": [
    "## Check the final dataset\n",
    "\n",
    "At the moment, since the plotters.show_attributes() and plotters.show_variables() are designed to work with netcdf files, I write the xarray dataset to netcdf before loading it and checking the attributes and variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Save the dataset to a NetCDF file\n",
    "# Check if the file exists and delete it if it does\n",
    "output_file = os.path.join('../data', 'test.nc')\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Save the dataset to a NetCDF file\n",
    "ds_renamed.to_netcdf(output_file, mode='w', format='NETCDF4_CLASSIC')\n",
    "\n",
    "# Show the attributes of the saved NetCDF file\n",
    "plotters.show_contents(output_file,'attrs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_file)\n",
    "output_file = '../data/sg015_20050213T230253_DT.nc'\n",
    "\n",
    "xr.open_dataset(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speeds(ds):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "    # Plot horizontal speed\n",
    "    ax[0].plot(ds['ctd_time'], ds['horz_speed'], label='Horizontal Speed', color='b')\n",
    "    ax[0].set_ylabel('Horizontal Speed (m/s)')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot vertical speed\n",
    "    ax[1].plot(ds['ctd_time'], ds['vert_speed'], label='Vertical Speed', color='r')\n",
    "    ax[1].set_ylabel('Vertical Speed (m/s)')\n",
    "    ax[1].set_xlabel('Time')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_speeds(ds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f329f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
